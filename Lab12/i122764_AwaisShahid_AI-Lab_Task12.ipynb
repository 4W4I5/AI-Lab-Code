{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def task1():\n",
    "    print(f\"{format('Task 1', '*^100')}\")\n",
    "    # 1. Load the dataset in Python\n",
    "    data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "    # 2. Clean the data\n",
    "    # Replace columns like Glucose, BloodPressure, SkinThickness, Insulin, BMI where value is 0 with mean of that column\n",
    "    checkForZeroes = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
    "    for col in checkForZeroes:\n",
    "        data[col] = data[col].replace(0, np.NaN)\n",
    "        mean = int(data[col].mean(skipna=True))\n",
    "        data[col] = data[col].replace(np.NaN, mean)\n",
    "\n",
    "    # 3. Separate the dependent and independent variables\n",
    "    x = data.iloc[:, 0:8]\n",
    "    y = data.iloc[:, 8]\n",
    "\n",
    "    # 4. Explore the data\n",
    "    # Heatmap\n",
    "    sns.heatmap(data.corr(), annot=True)\n",
    "    print(data.head())\n",
    "\n",
    "    # 5. Split the data into training and testing sets\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=0\n",
    "    )\n",
    "\n",
    "    # 6. Implement the KNN algorithm\n",
    "    def KNNClassifier(k):\n",
    "        # Create the KNN classifier with the specified value of K\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "        # Fit the classifier to the training data\n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = knn.predict(X_test)\n",
    "\n",
    "        # Print actual and predicted values\n",
    "        print(\"Actual values:\", y_test.values)\n",
    "        print(\"Predicted values:\", y_pred)\n",
    "\n",
    "    # Call the KNNClassifier function with different values of K\n",
    "    kValues = [1, 3, 5, 7, 9]\n",
    "    for k in kValues:\n",
    "        print(f\"K = {k}\")\n",
    "        KNNClassifier(k)\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "def task2():\n",
    "    print(f\"{format('Task 2', '*^100')}\")\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(\"Dataset2.csv\")\n",
    "\n",
    "    # Encoding categorical variables using one-hot encoding\n",
    "    data_encoded = pd.get_dummies(data)\n",
    "\n",
    "    def initialize_centroids(data, k):\n",
    "        initial_centroids = data.sample(n=k).values.astype(float)\n",
    "        return initial_centroids\n",
    "\n",
    "    def euclidean_distance(x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "    def assign_clusters(data, centroids):\n",
    "        clusters = []\n",
    "        for index, row in data.iterrows():\n",
    "            distances = [\n",
    "                euclidean_distance(row.values, centroid) for centroid in centroids\n",
    "            ]\n",
    "            closest_centroid = np.argmin(distances)\n",
    "            clusters.append(closest_centroid)\n",
    "        return clusters\n",
    "\n",
    "    def update_centroids(data, clusters, k):\n",
    "        new_centroids = []\n",
    "        df = pd.concat([data, pd.DataFrame(clusters, columns=[\"cluster\"])], axis=1)\n",
    "        for i in range(k):\n",
    "            cluster_data = df[df[\"cluster\"] == i].drop(\"cluster\", axis=1)\n",
    "            if not cluster_data.empty:\n",
    "                new_centroid = cluster_data.mean(axis=0)\n",
    "                new_centroids.append(new_centroid.values.astype(float))\n",
    "            else:\n",
    "                new_centroid = data.sample(1).values[0].astype(float)\n",
    "                new_centroids.append(new_centroid)\n",
    "        return np.array(new_centroids)\n",
    "\n",
    "    def k_means_clustering(data, k, max_iters=100):\n",
    "        centroids = initialize_centroids(data, k)\n",
    "        for _ in range(max_iters):\n",
    "            clusters = assign_clusters(data, centroids)\n",
    "            new_centroids = update_centroids(data, clusters, k)\n",
    "            if np.allclose(centroids, new_centroids, equal_nan=True):\n",
    "                break\n",
    "            centroids = new_centroids\n",
    "        return clusters, centroids\n",
    "\n",
    "    k = 10  # Number of clusters\n",
    "    clusters, centroids = k_means_clustering(data_encoded, k)\n",
    "    data_encoded[\"cluster\"] = clusters\n",
    "\n",
    "    # Displaying clusters\n",
    "    for i in range(k):\n",
    "        cluster_data = data_encoded[data_encoded[\"cluster\"] == i]\n",
    "        print(f\"Cluster {i+1} Data:\")\n",
    "        print(cluster_data.drop(\"cluster\", axis=1))\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        task1()\n",
    "        task2()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Execution interrupted by user\")\n",
    "        exit(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
